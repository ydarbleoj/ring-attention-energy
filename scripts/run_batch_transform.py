#!/usr/bin/env python3
"""Test script for batch transformation of all JSON files to Parquet.

This script runs the complete Transform stage on the entire dataset
using the BatchTransformOrchestrator for high-performance processing.
"""

import sys
from pathlib import Path
from datetime import datetime

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.core.pipeline.orchestrators.batch_transform_orchestrator import (
    BatchTransformOrchestrator,
    BatchTransformConfig
)


def run_full_batch_transform():
    """Run the complete batch transformation on all 548 files."""

    print("üöÄ EIA BATCH TRANSFORMATION - FULL DATASET")
    print("=" * 60)
    print(f"üïê Start time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()

    # Configure for aggressive performance
    config = BatchTransformConfig(
        files_per_batch=20,           # Larger batches for efficiency
        max_concurrent_batches=12,    # High concurrency
        validate_data=True,           # Keep data quality checks
        skip_empty_files=True,        # Skip files with 0 records
        overwrite_existing=False,     # Skip already processed files
        progress_update_interval=50   # Update every 50 files
    )

    # Initialize orchestrator
    orchestrator = BatchTransformOrchestrator(
        raw_data_path="data/raw/eia",
        interim_data_path="data/interim",
        config=config
    )

    # Run the complete transformation
    print("üîÑ Starting full dataset transformation...")
    results = orchestrator.transform_all_files()

    if results["success"]:
        print("\n‚úÖ TRANSFORMATION SUCCESSFUL!")

        # Show key metrics
        total_time = results["total_time_seconds"]
        files_processed = results["files_processed"]
        records_processed = results["total_output_records"]

        print(f"\nüìà KEY ACHIEVEMENTS:")
        print(f"  üéØ Target: Process 548 files in <5 minutes")
        print(f"  ‚úÖ Actual: {files_processed} files in {total_time:.1f} seconds ({total_time/60:.2f} minutes)")
        print(f"  üìä Records: {records_processed:,} total records processed")

        if "performance_metrics" in results:
            perf = results["performance_metrics"]
            print(f"  ‚ö° Speed: {perf['records_per_second']:,.0f} records/second")
            print(f"  üìÅ Throughput: {perf['files_per_second']:.1f} files/second")

        # Compare to target
        target_minutes = 5
        if total_time/60 < target_minutes:
            speedup = target_minutes / (total_time/60)
            print(f"  üèÜ SUCCESS: {speedup:.1f}x faster than target!")
        else:
            print(f"  ‚ö†Ô∏è  SLOWER: {(total_time/60)/target_minutes:.1f}x slower than target")

    else:
        print(f"\n‚ùå TRANSFORMATION FAILED: {results.get('error', 'Unknown error')}")

    return results


def run_test_subset():
    """Run a smaller test on a subset of files first."""

    print("üß™ EIA BATCH TRANSFORMATION - TEST SUBSET")
    print("=" * 50)

    # Test with just 2024 data first
    config = BatchTransformConfig(
        files_per_batch=10,
        max_concurrent_batches=6,
        validate_data=True,
        skip_empty_files=True,
        overwrite_existing=False,
        progress_update_interval=10
    )

    orchestrator = BatchTransformOrchestrator(
        raw_data_path="data/raw/eia",
        interim_data_path="data/interim",
        config=config
    )

    # Process only 2024 files as a test
    print("üîÑ Testing with 2024 files only...")
    results = orchestrator.transform_all_files(
        years=[2024],  # Filter to 2024 only
        regions=["PACW", "ERCO"]  # Test with 2 regions
    )

    if results["success"]:
        print(f"‚úÖ Test successful: {results['files_processed']} files in {results['total_time_seconds']:.1f}s")
        return True
    else:
        print(f"‚ùå Test failed: {results.get('error')}")
        return False


def run_progressive_test():
    """Run progressive testing: small ‚Üí medium ‚Üí full."""

    print("üìà PROGRESSIVE BATCH TRANSFORMATION TESTING")
    print("=" * 55)

    # Step 1: Test with 1 region, 1 year
    print("\nüîπ STEP 1: Single region, single year (PACW 2024)")
    config = BatchTransformConfig(
        files_per_batch=5,
        max_concurrent_batches=4,
        validate_data=True,
        skip_empty_files=True,
        overwrite_existing=False
    )

    orchestrator = BatchTransformOrchestrator(config=config)

    results1 = orchestrator.transform_all_files(
        regions=["PACW"],
        years=[2024]
    )

    if not results1["success"]:
        print(f"‚ùå Step 1 failed: {results1.get('error')}")
        return False

    print(f"‚úÖ Step 1: {results1['files_processed']} files, {results1['total_time_seconds']:.1f}s")

    # Step 2: Test with 2 regions, 2 years
    print("\nüîπ STEP 2: Multiple regions and years (PACW+ERCO, 2024+2025)")

    results2 = orchestrator.transform_all_files(
        regions=["PACW", "ERCO"],
        years=[2024, 2025]
    )

    if not results2["success"]:
        print(f"‚ùå Step 2 failed: {results2.get('error')}")
        return False

    print(f"‚úÖ Step 2: {results2['files_processed']} files, {results2['total_time_seconds']:.1f}s")

    # Step 3: Full dataset
    print("\nüîπ STEP 3: Full dataset (all regions, all years)")

    # Use more aggressive config for full run
    config.files_per_batch = 15
    config.max_concurrent_batches = 10
    orchestrator.batch_config = config

    results3 = orchestrator.transform_all_files()

    if results3["success"]:
        print(f"‚úÖ FULL SUCCESS: {results3['files_processed']} files in {results3['total_time_seconds']:.1f}s")

        # Final performance analysis
        total_time_min = results3['total_time_seconds'] / 60
        if total_time_min < 5:
            print(f"üèÜ ACHIEVEMENT UNLOCKED: Sub-5-minute transformation! ({total_time_min:.2f} minutes)")

        return results3
    else:
        print(f"‚ùå Full run failed: {results3.get('error')}")
        return False


if __name__ == "__main__":
    # Choose test mode based on command line argument
    import sys

    if len(sys.argv) > 1:
        mode = sys.argv[1].lower()
    else:
        mode = "progressive"  # Default

    if mode == "full":
        results = run_full_batch_transform()
    elif mode == "test":
        results = run_test_subset()
    elif mode == "progressive":
        results = run_progressive_test()
    else:
        print("Usage: python run_batch_transform.py [progressive|test|full]")
        print("  progressive: Small ‚Üí Medium ‚Üí Full testing (default)")
        print("  test: Quick test with subset of files")
        print("  full: Process complete 548-file dataset")
        sys.exit(1)

    print(f"\nüéØ NEXT STEPS:")
    print(f"1. Check data/interim/ for transformed Parquet files")
    print(f"2. Analyze data quality and completeness")
    print(f"3. Design Processed Stage aggregation strategy")
    print(f"4. Build ML/Ring-Attention optimized datasets")
